{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4406386,"sourceType":"datasetVersion","datasetId":1733714}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":" ## 19 april,\n\n## muse do it for using transfomration\n## networks graph, ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"This dataset contains 2 files:\n\nall Harry Potter books in txt file format.\nall Harry Potter books in txt file format, but i leave most of the special characters like [, \"]. (each sentence ends with '|' for easier splitting)\nI made a little preprocess on them and:\n\nremoved all unnecessary special characters and left in the text only [. ! ?] characters\n\nremoved all newline characters (\\n)\n\nremoved all carriage return (\\r) characters\n\nremoved all unnecessary text like page number or book title on each page\n\nadded white spaces before all special characters to treat them as separate tokens\n\nfixed all faulty words where:\nspecial character [. ! ?] was at the end of the word\nspecial character [. ! ?] was at the beginning of the word\nspecial character [. ! ?] was in the middle of the word","metadata":{}},{"cell_type":"code","source":"## rebel large model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\ntriplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic.\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n        if token == \"<triplet>\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"<subj>\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"<obj>\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:45:07.078716Z","iopub.execute_input":"2025-04-29T12:45:07.078964Z","iopub.status.idle":"2025-04-29T12:45:46.565391Z","shell.execute_reply.started":"2025-04-29T12:45:07.078936Z","shell.execute_reply":"2025-04-29T12:45:46.564563Z"}},"outputs":[{"name":"stderr","text":"2025-04-29 12:45:16.783659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745930716.976934      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745930717.031154      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa144584595e43fa855647cbdb2077f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba82344d2d8b465997f9a6e6ed96c1c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ae2f9c3b994da084ab4c3f6d1aef6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c6c52a774744d0839d9320aef4d788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7186b7feb6df4423942b61ce4948ef0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1826385b2184a738673330b4ead1f57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b8a3fb3df114879a6bb2f27aca4fc19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/344 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ea0e4517c449c4bb99d3cf5b1f893a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"<s><triplet> Punta Cana <subj> La Altagracia Province <obj> located in the administrative territorial entity <subj> Dominican Republic <obj> country <triplet> Higuey <subj> La Altagracia Province <obj> located in the administrative territorial entity <subj> Dominican Republic <obj> country <triplet> La Altagracia Province <subj> Dominican Republic <obj> country <triplet> Dominican Republic <subj> La Altagracia Province <obj> contains administrative territorial entity</s>\n[{'head': 'Punta Cana', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}, {'head': 'Punta Cana', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'Higuey', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}, {'head': 'Higuey', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'La Altagracia Province', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'Dominican Republic', 'type': 'contains administrative territorial entity', 'tail': 'La Altagracia Province'}]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def extract_sentences(file_path):\n    \"\"\"\n    Reads a text file where sentences are separated by '|'\n    and returns a list of cleaned sentences.\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        text = f.read()\n    # Split on '|' and strip whitespace\n    parts = text.split('|')\n    # Filter out any empty strings and strip leading/trailing whitespace\n    sentences = [p.strip() for p in parts if p.strip()]\n    return sentences\n\n\nsentences = extract_sentences('/kaggle/input/harry-potter-lstm/Harry_Potter_all_char_separated.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:52:04.449617Z","iopub.execute_input":"2025-04-29T12:52:04.449919Z","iopub.status.idle":"2025-04-29T12:52:04.589219Z","shell.execute_reply.started":"2025-04-29T12:52:04.449896Z","shell.execute_reply":"2025-04-29T12:52:04.588636Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentences[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:52:09.758893Z","iopub.execute_input":"2025-04-29T12:52:09.759204Z","iopub.status.idle":"2025-04-29T12:52:09.764490Z","shell.execute_reply.started":"2025-04-29T12:52:09.759183Z","shell.execute_reply":"2025-04-29T12:52:09.763886Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'Mr and Mrs Dursley , of number four , Privet Drive , were proud to say that they were perfectly normal , thank you very much .'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"for triplet in extracted_triplets:\n    print(triplet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:52:12.761903Z","iopub.execute_input":"2025-04-29T12:52:12.762204Z","iopub.status.idle":"2025-04-29T12:52:12.766709Z","shell.execute_reply.started":"2025-04-29T12:52:12.762182Z","shell.execute_reply":"2025-04-29T12:52:12.765848Z"}},"outputs":[{"name":"stdout","text":"{'head': 'Punta Cana', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}\n{'head': 'Punta Cana', 'type': 'country', 'tail': 'Dominican Republic'}\n{'head': 'Higuey', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}\n{'head': 'Higuey', 'type': 'country', 'tail': 'Dominican Republic'}\n{'head': 'La Altagracia Province', 'type': 'country', 'tail': 'Dominican Republic'}\n{'head': 'Dominican Republic', 'type': 'contains administrative territorial entity', 'tail': 'La Altagracia Province'}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:53:10.184149Z","iopub.execute_input":"2025-04-29T12:53:10.184858Z","iopub.status.idle":"2025-04-29T12:53:10.188082Z","shell.execute_reply.started":"2025-04-29T12:53:10.184834Z","shell.execute_reply":"2025-04-29T12:53:10.187479Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"len(sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T12:53:11.769544Z","iopub.execute_input":"2025-04-29T12:53:11.769803Z","iopub.status.idle":"2025-04-29T12:53:11.774415Z","shell.execute_reply.started":"2025-04-29T12:53:11.769785Z","shell.execute_reply":"2025-04-29T12:53:11.773798Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"79730"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"all_triplets = []\ni = 47999\nsentences = sentences[i:]\nfor curr_sentence in sentences:\n## add loop to this part of this code\n    extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(curr_sentence, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\n    extracted_triplets = extract_triplets(extracted_text[0])\n    for triplet in extracted_triplets:\n        all_triplets.append(triplet)\n    if(i%100==0):\n        print(f\"{i}th sentence has {len(extracted_triplets)}\")\n    if(i%1000==0):\n        df = pd.DataFrame(all_triplets, columns=['head', 'type', 'tail'])\n        df.to_csv(f'output_{i}.csv', index=False, encoding='utf-8')\n        print(\"Wrote\", len(df), \"rows to output.csv\")\n    i= i + 1\n\ndf = pd.DataFrame(all_triplets, columns=['head', 'type', 'tail'])\ndf.to_csv(f'output_{i}_final.csv', index=False, encoding='utf-8')\nprint(\"Wrote\", len(df), \"rows to output_final.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:05:58.574325Z","iopub.execute_input":"2025-04-29T13:05:58.574934Z"}},"outputs":[{"name":"stdout","text":"48000th sentence has 1\nWrote 3 rows to output.csv\n48100th sentence has 2\n48200th sentence has 2\n48300th sentence has 2\n48400th sentence has 1\n48500th sentence has 1\n48600th sentence has 2\n48700th sentence has 2\n48800th sentence has 1\n48900th sentence has 9\n49000th sentence has 1\nWrote 1997 rows to output.csv\n49100th sentence has 1\n49200th sentence has 2\n49300th sentence has 2\n49400th sentence has 2\n49500th sentence has 2\n49600th sentence has 2\n49700th sentence has 2\n49800th sentence has 2\n49900th sentence has 2\n50000th sentence has 2\nWrote 3891 rows to output.csv\n50100th sentence has 2\n50200th sentence has 2\n50300th sentence has 2\n50400th sentence has 1\n50500th sentence has 1\n50600th sentence has 1\n50700th sentence has 1\n50800th sentence has 1\n50900th sentence has 2\n51000th sentence has 1\nWrote 5913 rows to output.csv\n51100th sentence has 2\n51200th sentence has 2\n51300th sentence has 2\n51400th sentence has 2\n51500th sentence has 2\n51600th sentence has 2\n51700th sentence has 1\n51800th sentence has 2\n51900th sentence has 5\n52000th sentence has 1\nWrote 7954 rows to output.csv\n52100th sentence has 2\n52200th sentence has 1\n52300th sentence has 2\n52400th sentence has 4\n52500th sentence has 2\n52600th sentence has 2\n52700th sentence has 2\n52800th sentence has 2\n52900th sentence has 2\n53000th sentence has 2\nWrote 10043 rows to output.csv\n53100th sentence has 2\n53200th sentence has 5\n53300th sentence has 2\n53400th sentence has 3\n53500th sentence has 2\n53600th sentence has 2\n53700th sentence has 2\n53800th sentence has 1\n53900th sentence has 2\n54000th sentence has 1\nWrote 12056 rows to output.csv\n54100th sentence has 2\n54200th sentence has 4\n54300th sentence has 2\n54400th sentence has 1\n54500th sentence has 1\n54600th sentence has 1\n54700th sentence has 2\n54800th sentence has 2\n54900th sentence has 2\n55000th sentence has 2\nWrote 14030 rows to output.csv\n55100th sentence has 2\n55200th sentence has 1\n55300th sentence has 2\n55400th sentence has 3\n55500th sentence has 1\n55600th sentence has 2\n55700th sentence has 2\n55800th sentence has 2\n55900th sentence has 2\n56000th sentence has 2\nWrote 16020 rows to output.csv\n56100th sentence has 1\n56200th sentence has 1\n56300th sentence has 2\n56400th sentence has 2\n56500th sentence has 4\n56600th sentence has 2\n56700th sentence has 2\n56800th sentence has 2\n56900th sentence has 2\n57000th sentence has 3\nWrote 18013 rows to output.csv\n57100th sentence has 1\n57200th sentence has 1\n57300th sentence has 2\n57400th sentence has 2\n57500th sentence has 2\n57600th sentence has 1\n57700th sentence has 1\n57800th sentence has 2\n57900th sentence has 2\n58000th sentence has 2\nWrote 20008 rows to output.csv\n58100th sentence has 2\n58200th sentence has 2\n58300th sentence has 1\n58400th sentence has 2\n58500th sentence has 2\n58600th sentence has 1\n58700th sentence has 1\n58800th sentence has 2\n58900th sentence has 1\n59000th sentence has 2\nWrote 21912 rows to output.csv\n59100th sentence has 2\n59200th sentence has 3\n59300th sentence has 2\n59400th sentence has 2\n59500th sentence has 2\n59600th sentence has 2\n59700th sentence has 1\n59800th sentence has 1\n59900th sentence has 6\n60000th sentence has 2\nWrote 23991 rows to output.csv\n60100th sentence has 1\n60200th sentence has 2\n60300th sentence has 2\n60400th sentence has 1\n60500th sentence has 2\n60600th sentence has 2\n60700th sentence has 2\n60800th sentence has 1\n60900th sentence has 9\n61000th sentence has 2\nWrote 25976 rows to output.csv\n61100th sentence has 8\n61200th sentence has 2\n61300th sentence has 1\n61400th sentence has 3\n61500th sentence has 1\n61600th sentence has 2\n61700th sentence has 2\n61800th sentence has 1\n61900th sentence has 2\n62000th sentence has 2\nWrote 28031 rows to output.csv\n62100th sentence has 2\n62200th sentence has 1\n62300th sentence has 1\n62400th sentence has 2\n62500th sentence has 1\n62600th sentence has 1\n62700th sentence has 1\n62800th sentence has 1\n62900th sentence has 2\n63000th sentence has 2\nWrote 29959 rows to output.csv\n63100th sentence has 1\n63200th sentence has 2\n63300th sentence has 1\n63400th sentence has 1\n63500th sentence has 1\n63600th sentence has 2\n63700th sentence has 2\n63800th sentence has 1\n63900th sentence has 1\n64000th sentence has 2\nWrote 31958 rows to output.csv\n64100th sentence has 2\n64200th sentence has 2\n64300th sentence has 2\n64400th sentence has 1\n64500th sentence has 2\n64600th sentence has 1\n64700th sentence has 2\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\ndf = pd.DataFrame(all_triplets, columns=['head', 'type', 'tail'])\ndf.to_csv(f'final_output_{i}.csv', index=False, encoding='utf-8')\nprint(\"Wrote\", len(df), \"rows to output.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:38:39.049166Z","iopub.status.idle":"2025-04-17T20:38:39.049402Z","shell.execute_reply.started":"2025-04-17T20:38:39.049284Z","shell.execute_reply":"2025-04-17T20:38:39.049294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}